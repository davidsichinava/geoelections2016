install.packages(c("colorspace", "descr", "foreign", "manipulate", "RColorBrewer", "reshape2", "XLConnect"))
install.packages("knitr")
library(XML)
library(rvest)
library(plyr)
library(dplyr)
library(httr)
library(foreach)
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
dataTbl<-as.data.frame(url[5])
dataTbl<-as.data.frame(url[1])
dataTbl<-as.data.frame(url[2])
dataTbl<-as.data.frame(url[3])
dataTbl<-as.data.frame(url[4])
dataTbl<-as.data.frame(url[5])
dataTbl<-as.data.frame(url[6])
dataTbl<-as.data.frame(url[7])
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
dataTbl<-as.data.frame(url[7])
View(dataTbl)
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
dataTbl<-as.data.frame(url[1])
url
dataTbl<-as.data.frame(url[2])
t1data <-url%>%
html_node(".t2")%>%
html_table(fill=TRUE, header=TRUE)
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
t1data <-url%>%
html_node(".t1")%>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html_node("table2")%>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html() %>%
html_nodes(xpath='/html/body/table[2]/tbody/tr/td/table/tbody/tr[2]/td/center/table[2]') %>%
html_table()
url <- read_html("http://demoscope.ru/weekly/ssp/emp_lan_97_uezd.php?reg=949") # Get master page
t1data <-url%>%
read_html() %>%
html_nodes(xpath='/html/body/table[2]/tbody/tr/td/table/tbody/tr[2]/td/center/table[2]') %>%
html_table()
t1data <-url%>%
html_nodes(xpath='/html/body/table[2]/tbody/tr/td/table/tbody/tr[2]/td/center/table[2]') %>%
html_table()
View(dataTbl)
html_nodes(xpath='.table[2]') %>%
html_table()
t1data <-url%>%
html_nodes(xpath='.table[2]') %>%
html_table()
t1data <-url%>%
html_nodes("table") %>%
.[[2]] %>%
html_table()
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[1]] %>%
html_table()
t1data <-url%>%
html_nodes("table") %>%
.[[1]] %>%
html_table(fill=TRUE, header=TRUE)
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[3]] %>%
html_table(fill=TRUE, header=TRUE)
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[4]] %>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html_nodes("table") %>%
.[[5]] %>%
html_table(fill=TRUE, header=TRUE)
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[6]] %>%
html_table(fill=TRUE, header=TRUE)
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[7]] %>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html_nodes("table") %>%
.[[7]] %>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html_nodes("table") %>%
.[[8]] %>%
html_table(fill=TRUE, header=TRUE)
View(t1data)
guess_encoding()
t1data <-url%>%
html_nodes("table") %>%
.[[8]] %>%
html_table(fill=TRUE, header=TRUE) %>%
guess_encoding()
View(t1data)
t1data <-url%>%
html_nodes("table") %>%
.[[8]] %>%
html_table(fill=TRUE, header=TRUE) %>%
repair_encoding()
repair_encoding()
t1data <-url%>%
repair_encoding()%>%
html_nodes("table") %>%
.[[8]] %>%
html_table(fill=TRUE, header=TRUE)
t1data <-url%>%
html_nodes("table") %>%
.[[8]] %>%
html_table(fill=TRUE, header=TRUE)
t1data<-repair_encoding(t1data)
t1data<-repair_encoding(as.raw(t1data))
is.raw(t1data)
is.vector(t1data)
is.list(t1data)
source("http://gking.harvard.edu/zelig/install.R")
q()
library(XLConnect)
install.packages(c("curl", "httr"))
library(curl)
library(XML)
library(rvest)
library(plyr)
library(dplyr)
library(httr)
library(zoo)
library(gdata)
library(qpcR)
library(data.table)
library(stringr)
library(foreach)
library(curl)
setwd("D:\\Dropbox\\My Projects\\Elections\\Geogia 2016 Parliamentary\\github\\geoelections2016")
## Scrape precinct-level Proportional results
## Get URLs for each majoritarian district
mURL<-"http://results.cec.gov.ge/proporciuli.html" # Assign master page url
url <- html_session(mURL) # Get master page
urls <- url %>% # feed `main.page` to the next step
html_nodes("a") %>% # get the CSS nodes
html_attr("href") # extract the URLs
dfURL <- data.frame(urls = urls, stringsAsFactors = FALSE)
## Subset those districts which have data
dfURL<-as.data.frame(dfURL[grep("*olq*", dfURL$urls), ])
names(dfURL)<-c("urls")
dfURL<-(dfURL[grep("*olq*", dfURL$urls), ])
dfURL<-as.data.frame(paste0("http://results.cec.gov.ge/", dfURL, sep=""))
## Loop thourgh URLs and get data tables for each majoritarian district
## Create an empty data frame for pasting precinct level results
PropData <- as.data.frame(setNames(replicate(27,numeric(0), simplify = F), letters[1:27]))
for(i in 1:nrow(dfURL)) {
scrURL<-html_session(paste0("http://results.cec.gov.ge/", (dfURL$urls[i]), sep=""))
propRaw<-scrURL%>%
read_html() %>%
html_nodes(xpath='//*[(@id = "table36")]')%>%
html_table(fill=TRUE, header=TRUE)
propRaw<-as.data.frame(propRaw)
PropData<-rbind(PropData, propRaw)
}
View(dfURL)
scrURL<-html_session("http://results.cec.gov.ge/olq_2.html")
propRaw<-scrURL%>%
read_html(handle = curl::new_handle("useragent" = "Mozilla/5.0"), encoding = "UTF-8") %>%
html_nodes(xpath='//*[(@id = "table36")]')%>%
html_table(fill=TRUE, header=TRUE)
propRaw<-as.data.frame(propRaw)
PropData<-rbind(PropData, propRaw)
View(PropData)
page2 <- GET("http://results.cec.gov.ge/olq_2.html", user_agent("Mozilla/5.0 (Windows NT 6.1; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0")) %>%
read_html() %>%
html_nodes(xpath='//*[(@id = "table36")]')%>%
html_table(fill=TRUE, header=TRUE)
propRaw<-as.data.frame(propRaw)
PropData<-rbind(PropData, propRaw)
View(PropData)
PropData <- as.data.frame(setNames(replicate(27,numeric(0), simplify = F), letters[1:27]))
for(i in 1:nrow(dfURL)) {
scrURL <- GET(paste0("http://results.cec.gov.ge/", (dfURL$urls[i]), sep=""), user_agent("Mozilla/5.0 (Windows NT 6.1; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0")) %>%
read_html() %>%
html_nodes(xpath='//*[(@id = "table36")]')%>%
html_table(fill=TRUE, header=TRUE)
propRaw<-as.data.frame(propRaw)
PropData<-rbind(PropData, propRaw)
}
